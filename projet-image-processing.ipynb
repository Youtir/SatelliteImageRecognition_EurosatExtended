{"cells":[{"metadata":{"id":"gzr3efTVQWYR","trusted":true},"cell_type":"code","source":"import numpy as np\nimport json\nimport tensorflow as tf\n\n# download dataset from json object\nf = open(r'../input/ships-in-satellite-imagery/shipsnet.json')\ndataset = json.load(f)\nf.close()\n\nindices = [index for index, element in enumerate(dataset[\"labels\"]) if element == 1]\nimagesships = np.array([dataset['data'][i] for i in indices]).astype('uint8')\nyships = np.array([dataset['labels'][i] for i in indices])\nyships = np.where(yships==1, 11, yships)\n\ncolor_chanels = 3\nweight = 80\nheight = 80\nXships = imagesships.reshape([-1, color_chanels, weight, height])\nXships = np.moveaxis(Xships,1,3)\n\n\ni_width = 64\ni_height = 64\n\nXships = tf.image.resize(Xships, [i_height, i_width]).numpy()","execution_count":null,"outputs":[]},{"metadata":{"id":"fh6acU-AZvfK","outputId":"4f000462-2c25-467c-d593-bf8793a76769","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, axes = plt.subplots(10,10, figsize=(20,20))\nfor i,ax in enumerate(axes.flat):\n    ax.imshow(Xships[i].astype('uint8'))","execution_count":null,"outputs":[]},{"metadata":{"id":"G3ow_PoVcxax"},"cell_type":"markdown","source":"# **Planes Import**"},{"metadata":{"id":"ueTvITtlRSHX","trusted":true},"cell_type":"code","source":"# download dataset from json object\nss = open(r'../input/planesnet/planesnet/planesnet.json')\ndataset = json.load(ss)\nss.close()\n\nindices = [index for index, element in enumerate(dataset[\"labels\"]) if element == 1]\nimagesplanes = np.array([dataset['data'][i] for i in indices]).astype('uint8')\nyplanes = np.array([dataset['labels'][i] for i in indices])\nyplanes = np.where(yplanes==1, 12, yplanes)\nXplanes = imagesplanes.reshape([-1,3, 20, 20])\nXplanes = np.moveaxis(Xplanes,1,3)\n\nXplanes = tf.image.resize(Xplanes, [i_height, i_width]).numpy()","execution_count":null,"outputs":[]},{"metadata":{"id":"2NTMLInp3rIy","outputId":"e8a879ba-d41d-453b-8958-d8e33a02e990","trusted":true},"cell_type":"code","source":"fig1, axes = plt.subplots(10,10, figsize=(20,20))\nfor i,ax in enumerate(axes.flat):\n    ax.imshow(Xplanes[i].astype('uint8'))","execution_count":null,"outputs":[]},{"metadata":{"id":"CIQMbG1pTx2h","trusted":true},"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom glob import glob\ndef read_img(location):\n  data = []\n  labels = []\n  dirs = os.listdir(location)\n  for i in dirs:\n    print(location+i+'/')\n    for pic in glob(location+i+'/*.jpg'):\n      im = Image.open(pic)\n      im = np.array(im)\n      data.append(im)\n      labels.append(i)\n  return np.array(data),np.array(labels)","execution_count":null,"outputs":[]},{"metadata":{"id":"FNAiRonhRZ_j","outputId":"fc33b0be-475f-4a90-fde5-d375ab0ea154","trusted":true},"cell_type":"code","source":"X_eurosat,y_eurosat = read_img(r'../input/eurosat-dataset/EuroSAT/')","execution_count":null,"outputs":[]},{"metadata":{"id":"xJl3zdBuc4jq","outputId":"3fdae60f-c46e-46fc-961f-2f3fd9a2e931","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, axes = plt.subplots(10,10, figsize=(8,8))\nfor i,ax in enumerate(axes.flat):\n    ax.imshow(X_eurosat[i])","execution_count":null,"outputs":[]},{"metadata":{"id":"qA3ESC1gd5RQ","outputId":"ecf655a6-f31f-4d94-c0fc-5b96235ec9dd","trusted":true},"cell_type":"code","source":"Xplanes.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"K8b_ouvM5wsf","outputId":"cc6867a8-89a0-4430-8581-599d78a25cd4","trusted":true},"cell_type":"code","source":"Xships.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"JTP0RZry6F8p","outputId":"6fb80330-3b52-4f26-8255-d552eed925b4","trusted":true},"cell_type":"code","source":"X_eurosat.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"gFzeqhE89tlE","outputId":"b767818d-e4c9-4810-c172-7cd7e4e1236e","trusted":true},"cell_type":"code","source":"np.unique(y_eurosat)","execution_count":null,"outputs":[]},{"metadata":{"id":"LEwHW9BHtG5G","trusted":true},"cell_type":"code","source":"labels_euro=y_eurosat.copy()\nlabels_euro[labels_euro == \"AnnualCrop\"] = 1\nlabels_euro[labels_euro == \"Forest\"] = 2\nlabels_euro[labels_euro == \"HerbaceousVegetation\"] = 3\nlabels_euro[labels_euro == \"Highway\"] = 4\nlabels_euro[labels_euro == \"Industrial\"] = 5\nlabels_euro[labels_euro == \"Pasture\"] = 6\nlabels_euro[labels_euro == \"PermanentCrop\"] = 7\nlabels_euro[labels_euro == \"Residential\"] = 8\nlabels_euro[labels_euro == \"River\"] = 9\nlabels_euro[labels_euro == \"SeaLake\"] = 10","execution_count":null,"outputs":[]},{"metadata":{"id":"-UL8ewOEuETx","outputId":"9dad8301-a357-444e-f69d-060a13e24456","trusted":true},"cell_type":"code","source":"labels_euro","execution_count":null,"outputs":[]},{"metadata":{"id":"3ql8xRwGFDd9","outputId":"e3038804-9bbb-4188-fa42-7075110bc527","trusted":true},"cell_type":"code","source":"print(Xships.shape)\nprint(Xplanes.shape)\nprint(X_eurosat.shape)\nprint(yships.shape)\nprint(yplanes.shape)\nprint(labels_euro.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"J2cVwhHwuUy8","trusted":true},"cell_type":"code","source":"Xdata = np.concatenate((Xships,Xplanes,X_eurosat))\nYdata = np.concatenate((yships,yplanes,labels_euro))","execution_count":null,"outputs":[]},{"metadata":{"id":"XMqwzFKPGk2D","outputId":"f2050866-d70b-4e12-c1f3-8af07005b1d7","trusted":true},"cell_type":"code","source":"print(Xdata.shape)\nprint(Ydata.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"t39KmYDSnuH7","outputId":"4cf3a6e1-7e77-45bc-9e56-64e66837f529","trusted":true},"cell_type":"code","source":"Ydata","execution_count":null,"outputs":[]},{"metadata":{"id":"D1YBjVz1pZaH","trusted":true},"cell_type":"code","source":"labels_indices={\n    1: \"AnnualCrop\",\n    2:\"Forest\",\n    3:\"HerbaceousVegetation\",\n    4:\"Highway\",\n    5:\"Industrial\",\n    6:\"Pasture\",\n    7:\"PermanentCrop\",\n    8:\"Residential\" ,\n    9:\"River\",\n    10:\"SeaLake\",\n    11:\"Ships\",\n    12:\"Planes\"\n    \n}\n","execution_count":null,"outputs":[]},{"metadata":{"id":"JwSif2yUmqtr","outputId":"44621939-13df-48c5-a981-1c0a35ed55a7","trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# plot class distributions of whole dataset\nunique, counts = np.unique(Ydata, return_counts=True)\ncounts = dict(zip(unique, counts))\n\n\n\nplt.figure(figsize=(10, 5))\n\nplt.bar(range(len(counts)), list(counts.values()), align='center')\nplt.xticks(range(len(counts)), list(counts.keys()), fontsize=12, rotation=80)\nplt.xlabel('class label', fontsize=13)\nplt.ylabel('class size', fontsize=13)\nplt.title('EUROSAT+ships+planes Class Distribution', fontsize=15);","execution_count":null,"outputs":[]},{"metadata":{"id":"x7boJmrJG2RF"},"cell_type":"markdown","source":"# **Construction du Mod√®le**"},{"metadata":{"id":"T54hHutkGu7N","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.backend import set_image_data_format\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\nfrom tensorflow.keras import optimizers, losses, utils\nfrom sklearn.metrics import classification_report\nimport numpy as np\n\nX_train, X_test, y_train, y_test = train_test_split(X_eurosat, labels_euro, train_size=0.9, test_size=0.1, shuffle=True, random_state=42)\n\n\ny_train = tf.one_hot(y_train, depth=10)\n\n\n\nmodel = Sequential() \nmodel.add(Conv2D(28, (3, 3), padding=\"same\",input_shape=(64, 64, 3))) \nmodel.add(Activation(\"relu\")) \nmodel.add(Conv2D(28, (3, 3), padding=\"same\")) \nmodel.add(Activation(\"relu\")) \nmodel.add(MaxPool2D(2,2)) \nmodel.add(Conv2D(56, (3, 3),padding=\"same\")) \nmodel.add(Activation(\"relu\")) \nmodel.add(Conv2D(56, (3, 3), padding=\"same\")) \nmodel.add(Activation(\"relu\")) \nmodel.add(MaxPool2D(2,2)) \nmodel.add(Conv2D(112, (3, 3), padding=\"same\")) \nmodel.add(Activation(\"relu\")) \nmodel.add(Conv2D(112, (3, 3), padding=\"same\")) \nmodel.add(Activation(\"relu\")) \nmodel.add(MaxPool2D(2,2)) \nmodel.add(Flatten()) \nmodel.add(Dense(784)) \nmodel.add(Activation(\"relu\")) \nmodel.add(Dropout(0.6)) \nmodel.add(Dense(10)) \nmodel.add(Activation(\"sigmoid\")) \nadam = optimizers.Adam(lr=0.00001)\nmodel.compile(optimizer=adam, loss=losses.binary_crossentropy, metrics=['categorical_accuracy'])\n\nmodel.fit(X_train, y_train, validation_split=0.07, epochs = 30)\n\ny_test = tf.one_hot(y_test, depth=10)\n\nmodel.evaluate(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.backend import set_image_data_format\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\nfrom tensorflow.keras import optimizers, losses, utils\nfrom sklearn.metrics import classification_report\nimport numpy as np\n\nXdata = np.concatenate((Xships,X_eurosat))\nYdata = np.concatenate((yships,labels_euro))\n\nX_train, X_test, y_train, y_test = train_test_split(Xdata, Ydata, train_size=0.8, test_size=0.2, shuffle=True, random_state=42)\n\n\ny_train = tf.one_hot(y_train, depth=11)\n\n\nmodel = Sequential() \nmodel.add(Conv2D(28, (3, 3), padding=\"same\",input_shape=(64, 64, 3))) \nmodel.add(Activation(\"relu\")) \nmodel.add(Conv2D(28, (3, 3), padding=\"same\")) \nmodel.add(Activation(\"relu\")) \nmodel.add(MaxPool2D(2,2)) \nmodel.add(Conv2D(56, (3, 3),padding=\"same\")) \nmodel.add(Activation(\"relu\")) \nmodel.add(Conv2D(56, (3, 3), padding=\"same\")) \nmodel.add(Activation(\"relu\")) \nmodel.add(MaxPool2D(2,2)) \nmodel.add(Conv2D(112, (3, 3), padding=\"same\")) \nmodel.add(Activation(\"relu\")) \nmodel.add(Conv2D(112, (3, 3), padding=\"same\")) \nmodel.add(Activation(\"relu\")) \nmodel.add(MaxPool2D(2,2)) \nmodel.add(Flatten()) \nmodel.add(Dense(784)) \nmodel.add(Activation(\"relu\")) \nmodel.add(Dropout(0.6)) \nmodel.add(Dense(11)) \nmodel.add(Activation(\"sigmoid\")) \nadam = optimizers.Adam(lr=0.0001)\nmodel.compile(optimizer=adam, loss=losses.binary_crossentropy, metrics=['categorical_accuracy'])\n\nmodel.fit(X_train, y_train, validation_split=0.07, epochs = 30)\n\ny_test = tf.one_hot(y_test, depth=11)\n\nmodel.evaluate(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.backend import set_image_data_format\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\nfrom tensorflow.keras import optimizers, losses, utils\nfrom sklearn.metrics import classification_report\nimport numpy as np\n\n\nXdata = np.concatenate((Xships,Xplanes[:3000],X_eurosat))\nYdata = np.concatenate((yships,yplanes[:3000],labels_euro))\n\nX_train, X_test, y_train, y_test = train_test_split(Xdata, Ydata, train_size=0.8, test_size=0.2, shuffle=True, random_state=42)\n\n\ny_train = tf.one_hot(y_train, depth=12)\n\n\n\nmodel = Sequential() \nmodel.add(Conv2D(28, (3, 3), padding=\"same\",input_shape=(64, 64, 3))) \nmodel.add(Activation(\"relu\")) \nmodel.add(Conv2D(28, (3, 3), padding=\"same\")) \nmodel.add(Activation(\"relu\")) \nmodel.add(MaxPool2D(2,2)) \nmodel.add(Conv2D(56, (3, 3),padding=\"same\")) \nmodel.add(Activation(\"relu\")) \nmodel.add(Conv2D(56, (3, 3), padding=\"same\")) \nmodel.add(Activation(\"relu\")) \nmodel.add(MaxPool2D(2,2)) \nmodel.add(Conv2D(112, (3, 3), padding=\"same\")) \nmodel.add(Activation(\"relu\")) \nmodel.add(Conv2D(112, (3, 3), padding=\"same\")) \nmodel.add(Activation(\"relu\")) \nmodel.add(MaxPool2D(2,2)) \nmodel.add(Flatten()) \nmodel.add(Dense(784)) \nmodel.add(Activation(\"relu\")) \nmodel.add(Dropout(0.6)) \nmodel.add(Dense(12)) \nmodel.add(Activation(\"sigmoid\")) \nadam = optimizers.Adam(lr=0.00001)\nmodel.compile(optimizer=adam, loss=losses.binary_crossentropy, metrics=['categorical_accuracy'])\n\nmodel.fit(X_train, y_train, validation_split=0.07, epochs = 30)\n\ny_test = tf.one_hot(y_test, depth=12)\n\nY_test = np.argmax(y_test, axis=1)+1 # Convert one-hot to index\ny_pred = model.predict_classes(X_test)\nprint(classification_report(Y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}